{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import pearsonr\n",
    "from heapq import heappush, heappop, heappushpop\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import LinearSVC\n",
    "import itertools\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## cat vs cat\n",
    "\n",
    "#import data\n",
    "best_feature_vectors = np.load(\"features_train.npy\")\n",
    "test_feature_vectors = np.load(\"features_test.npy\")\n",
    "lengths = np.load(\"category_lengths.npy\")\n",
    "category_info = np.load(\"words_in_categories.npy\")\n",
    "\n",
    "#define constants\n",
    "toSelect = 5\n",
    "tEx = 10\n",
    "training_amt = 8\n",
    "testing_amt = 2\n",
    "\n",
    "#dictionaries to pickle data later\n",
    "save_trainx = {}\n",
    "save_trainy = {}\n",
    "save_testx = {}\n",
    "save_testy = {}\n",
    "\n",
    "#loop through all pairs of categories\n",
    "for cat1 in range(12):\n",
    "    for cat2 in range(cat1+1, 12):\n",
    "        \n",
    "        tot_words = int(lengths[cat1][0])+int(lengths[cat2][0])\n",
    "        \n",
    "        #create empty train and test matrices\n",
    "        trainx = np.zeros((0,toSelect * tEx))\n",
    "        trainy = np.zeros((training_amt * tot_words))\n",
    "        testx = np.zeros((0, toSelect * tEx))\n",
    "        testy = np.zeros((testing_amt * tot_words))\n",
    "        \n",
    "        ytraincnt = 0\n",
    "        ytestcnt = 0\n",
    "        \n",
    "        #loop through every presentation (training_amt = 8)\n",
    "        for pres in range(training_amt):\n",
    "            #loop through every word that is in the first category\n",
    "            for cat1_word in category_info[cat1]:\n",
    "                if cat1_word != -1:\n",
    "                    #add the feature vector of that word to the train matrix\n",
    "                    trainx = np.concatenate((trainx, np.reshape(best_feature_vectors[cat1_word][pres],(1,toSelect*tEx))), axis=0)\n",
    "                    #since this is the first category, it will be a '0' in the y-vector\n",
    "                    trainy[ytraincnt] = 0\n",
    "                    ytraincnt+=1\n",
    "                    \n",
    "                    #do the same thing for test, but only testing_amt = 2 number of times \n",
    "                    if(pres<testing_amt):\n",
    "                        testx = np.concatenate((testx, np.reshape(test_feature_vectors[cat1_word][pres],(1,toSelect*tEx))), axis=0)\n",
    "                        testy[ytestcnt] = 0\n",
    "                        ytestcnt+=1\n",
    "\n",
    "            #repeat above procedure for the second category\n",
    "            for cat2_word in category_info[cat2]:\n",
    "                if cat2_word != -1:\n",
    "                    trainx = np.concatenate((trainx, np.reshape(best_feature_vectors[cat2_word][pres],(1,toSelect*tEx))), axis=0)\n",
    "                    #now there is a '1' in the y-vector\n",
    "                    trainy[ytraincnt] = 1\n",
    "                    ytraincnt+=1\n",
    "                    \n",
    "                    if(pres<testing_amt):\n",
    "                        testx = np.concatenate((testx, np.reshape(test_feature_vectors[cat2_word][pres],(1,toSelect*tEx))), axis=0)\n",
    "                        testy[ytestcnt] = 1\n",
    "                        ytestcnt+=1 \n",
    "                        \n",
    "        #create dictionaries of the matrices              \n",
    "        save_trainx[(cat1,cat2)] = trainx\n",
    "        save_trainy[(cat1,cat2)] = trainy\n",
    "        save_testx[(cat1,cat2)] = testx\n",
    "        save_testy[(cat1,cat2)] = testy\n",
    "\n",
    "#save data as CategoryXCategory\n",
    "pickle.dump((save_trainx, save_trainy, save_testx, save_testy), open(\"CategoryXCategory.p\",\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Vehicles and Insects we picked C = 2.00923300257\n",
      "Has accuracy 0.65\n",
      "=========\n",
      "For Furniture and Building Parts we picked C = 14.1747416293\n",
      "Has accuracy 0.75\n",
      "=========\n",
      "For Animals and Body Parts we picked C = 18.7381742286\n",
      "Has accuracy 0.7\n",
      "=========\n",
      "For Vegetables and Man-made objects we picked C = 24.7707635599\n",
      "Has accuracy 0.8\n",
      "=========\n",
      "For Furniture and Clothing we picked C = 6.13590727341\n",
      "Has accuracy 0.5\n",
      "=========\n",
      "For Vehicles and Kitchen Utensils we picked C = 0.657933224658\n",
      "Has accuracy 0.75\n",
      "=========\n",
      "For Buildings and Clothing we picked C = 4.64158883361\n",
      "Has accuracy 0.708333333333\n",
      "=========\n",
      "For Body Parts and Man-made objects we picked C = 1.1497569954\n",
      "Has accuracy 0.8\n",
      "=========\n",
      "For Tools and Building Parts we picked C = 0.756463327555\n",
      "Has accuracy 0.772727272727\n",
      "=========\n",
      "For Furniture and Kitchen Utensils we picked C = 0.376493580679\n",
      "Has accuracy 0.65\n",
      "=========\n",
      "For Clothing and Insects we picked C = 7.05480231072\n",
      "Has accuracy 0.65\n",
      "=========\n",
      "For Animals and Kitchen Utensils we picked C = 100.0\n",
      "Has accuracy 0.5\n",
      "=========\n",
      "For Tools and Vegetables we picked C = 0.0533669923121\n",
      "Has accuracy 0.772727272727\n",
      "=========\n",
      "For Body Parts and Building Parts we picked C = 4.0370172586\n",
      "Has accuracy 0.65\n",
      "=========\n",
      "For Building Parts and Man-made objects we picked C = 21.5443469003\n",
      "Has accuracy 0.8\n",
      "=========\n",
      "For Tools and Body Parts we picked C = 0.572236765935\n",
      "Has accuracy 0.863636363636\n",
      "=========\n",
      "For Animals and Man-made objects we picked C = 0.0613590727341\n",
      "Has accuracy 0.35\n",
      "=========\n",
      "For Buildings and Vehicles we picked C = 2.00923300257\n",
      "Has accuracy 0.75\n",
      "=========\n",
      "For Vehicles and Clothing we picked C = 0.0932603346883\n",
      "Has accuracy 0.65\n",
      "=========\n",
      "For Animals and Buildings we picked C = 0.756463327555\n",
      "Has accuracy 0.625\n",
      "=========\n",
      "For Furniture and Insects we picked C = 0.284803586844\n",
      "Has accuracy 0.8\n",
      "=========\n",
      "For Buildings and Insects we picked C = 1.51991108295\n",
      "Has accuracy 0.75\n",
      "=========\n",
      "For Animals and Vehicles we picked C = 1.51991108295\n",
      "Has accuracy 0.8\n",
      "=========\n",
      "For Body Parts and Vegetables we picked C = 49.7702356433\n",
      "Has accuracy 0.6\n",
      "=========\n",
      "For Kitchen Utensils and Vegetables we picked C = 32.7454916288\n",
      "Has accuracy 0.75\n",
      "=========\n",
      "For Clothing and Vegetables we picked C = 1.1497569954\n",
      "Has accuracy 0.85\n",
      "=========\n",
      "For Furniture and Vehicles we picked C = 14.1747416293\n",
      "Has accuracy 0.45\n",
      "=========\n",
      "For Tools and Man-made objects we picked C = 24.7707635599\n",
      "Has accuracy 0.5\n",
      "=========\n",
      "For Insects and Man-made objects we picked C = 6.13590727341\n",
      "Has accuracy 0.7\n",
      "=========\n",
      "For Building Parts and Vegetables we picked C = 0.327454916288\n",
      "Has accuracy 0.7\n",
      "=========\n",
      "For Tools and Furniture we picked C = 18.7381742286\n",
      "Has accuracy 0.5\n",
      "=========\n",
      "For Animals and Vegetables we picked C = 2.00923300257\n",
      "Has accuracy 0.7\n",
      "=========\n",
      "For Body Parts and Vehicles we picked C = 32.7454916288\n",
      "Has accuracy 0.55\n",
      "=========\n",
      "For Furniture and Vegetables we picked C = 5.33669923121\n",
      "Has accuracy 0.7\n",
      "=========\n",
      "For Buildings and Kitchen Utensils we picked C = 0.0613590727341\n",
      "Has accuracy 0.625\n",
      "=========\n",
      "For Body Parts and Kitchen Utensils we picked C = 0.0705480231072\n",
      "Has accuracy 0.7\n",
      "=========\n",
      "For Vehicles and Man-made objects we picked C = 32.7454916288\n",
      "Has accuracy 0.7\n",
      "=========\n",
      "For Kitchen Utensils and Man-made objects we picked C = 16.2975083462\n",
      "Has accuracy 0.65\n",
      "=========\n",
      "For Clothing and Man-made objects we picked C = 3.05385550883\n",
      "Has accuracy 0.7\n",
      "=========\n",
      "For Buildings and Building Parts we picked C = 0.497702356433\n",
      "Has accuracy 0.708333333333\n",
      "=========\n",
      "For Animals and Furniture we picked C = 57.2236765935\n",
      "Has accuracy 0.6\n",
      "=========\n",
      "For Buildings and Vegetables we picked C = 0.572236765935\n",
      "Has accuracy 0.666666666667\n",
      "=========\n",
      "For Insects and Vegetables we picked C = 1.0\n",
      "Has accuracy 0.8\n",
      "=========\n",
      "For Body Parts and Insects we picked C = 21.5443469003\n",
      "Has accuracy 0.65\n",
      "=========\n",
      "For Tools and Vehicles we picked C = 1.1497569954\n",
      "Has accuracy 0.818181818182\n",
      "=========\n",
      "For Animals and Insects we picked C = 16.2975083462\n",
      "Has accuracy 0.6\n",
      "=========\n",
      "For Kitchen Utensils and Building Parts we picked C = 32.7454916288\n",
      "Has accuracy 0.8\n",
      "=========\n",
      "For Tools and Clothing we picked C = 28.4803586844\n",
      "Has accuracy 0.636363636364\n",
      "=========\n",
      "For Furniture and Man-made objects we picked C = 9.32603346883\n",
      "Has accuracy 0.6\n",
      "=========\n",
      "For Building Parts and Insects we picked C = 6.13590727341\n",
      "Has accuracy 0.75\n",
      "=========\n",
      "For Tools and Animals we picked C = 14.1747416293\n",
      "Has accuracy 0.590909090909\n",
      "=========\n",
      "For Kitchen Utensils and Insects we picked C = 32.7454916288\n",
      "Has accuracy 0.65\n",
      "=========\n",
      "For Vehicles and Vegetables we picked C = 14.1747416293\n",
      "Has accuracy 0.65\n",
      "=========\n",
      "For Kitchen Utensils and Clothing we picked C = 65.7933224658\n",
      "Has accuracy 0.65\n",
      "=========\n",
      "For Body Parts and Furniture we picked C = 65.7933224658\n",
      "Has accuracy 0.65\n",
      "=========\n",
      "For Vehicles and Building Parts we picked C = 75.6463327555\n",
      "Has accuracy 0.65\n",
      "=========\n",
      "For Buildings and Man-made objects we picked C = 0.869749002618\n",
      "Has accuracy 0.708333333333\n",
      "=========\n",
      "For Buildings and Furniture we picked C = 14.1747416293\n",
      "Has accuracy 0.75\n",
      "=========\n",
      "For Body Parts and Clothing we picked C = 8.1113083079\n",
      "Has accuracy 0.6\n",
      "=========\n",
      "For Tools and Kitchen Utensils we picked C = 75.6463327555\n",
      "Has accuracy 0.590909090909\n",
      "=========\n",
      "For Animals and Clothing we picked C = 75.6463327555\n",
      "Has accuracy 0.5\n",
      "=========\n",
      "For Animals and Building Parts we picked C = 37.6493580679\n",
      "Has accuracy 0.6\n",
      "=========\n",
      "For Tools and Insects we picked C = 1.51991108295\n",
      "Has accuracy 0.727272727273\n",
      "=========\n",
      "For Buildings and Body Parts we picked C = 0.107226722201\n",
      "Has accuracy 0.666666666667\n",
      "=========\n",
      "For Building Parts and Clothing we picked C = 14.1747416293\n",
      "Has accuracy 0.75\n",
      "=========\n",
      "For Tools and Buildings we picked C = 49.7702356433\n",
      "Has accuracy 0.730769230769\n",
      "=========\n",
      "0.674421664194\n"
     ]
    }
   ],
   "source": [
    "## cat vs cat\n",
    "\n",
    "index_to_cat = [\"Tools\",\"Animals\",\"Buildings\",\"Body Parts\",\"Furniture\",\"Vehicles\",\"Kitchen Utensils\", \n",
    "\"Building Parts\", \"Clothing\", \"Insects\", \"Vegetables\",\"Man-made objects\"]\n",
    "\n",
    "#load in matrices and extract data\n",
    "file_name = 'CategoryXCategory.p' #change this appropriately\n",
    "loaded_data = pickle.load(open(file_name,\"rb\"))\n",
    "\n",
    "dict_trainx = loaded_data[0]\n",
    "dict_trainy = loaded_data[1]\n",
    "dict_testx = loaded_data[2]\n",
    "dict_testy = loaded_data[3]\n",
    "\n",
    "clist = np.logspace(-4,2,100)\n",
    "\n",
    "#restating important constants, in case the two programs are not run together\n",
    "training_amt = 8 #num of presentations used for training\n",
    "testing_amt = 2 #num of presentations used for testing\n",
    "toSelect = 5 #num of btc's selected\n",
    "tEx = 10 #number of features per BTC vector\n",
    "\n",
    "#loop through each pair of categories\n",
    "avgacc = 0\n",
    "for pair in dict_trainx:\n",
    "    trainx = dict_trainx[pair]\n",
    "    trainy = dict_trainy[pair]\n",
    "    testx = dict_testx[pair]\n",
    "    testy = dict_testy[pair]\n",
    "\n",
    "    bst_acc = 0\n",
    "    bst_c = 0\n",
    "    \n",
    "    #cross validation to find the best C value (stored as bst_c)\n",
    "    for c in clist:\n",
    "        cross_avg_acc = 0\n",
    "        for fold in range(4):\n",
    "            fold_sz = int(trainx.shape[0]/4)\n",
    "            valid_x = trainx[(fold_sz*fold):((fold_sz)*(fold+1))]\n",
    "            valid_y = trainy[(fold_sz*fold):((fold_sz)*(fold+1))]\n",
    "            tr_x = np.concatenate((trainx[:(fold_sz*fold)],trainx[((fold+1)*fold_sz):]), axis = 0)\n",
    "            tr_y = np.concatenate((trainy[:(fold_sz*fold)],trainy[((fold+1)*fold_sz):]), axis = 0)\n",
    "            \n",
    "            #normalize data by having 0 mean and unit variance\n",
    "            scaler = StandardScaler()\n",
    "            tr_x = scaler.fit_transform(tr_x)\n",
    "            valid_x = scaler.transform(valid_x)\n",
    "            tr_y = np.ravel(tr_y)\n",
    "            valid_y = np.ravel(valid_y)\n",
    "\n",
    "            classifier = LinearSVC(C = c)\n",
    "            classifier.fit(tr_x,tr_y)\n",
    "            cross_avg_acc += (classifier.score(valid_x, valid_y))/4.0\n",
    "        if(cross_avg_acc > bst_acc):\n",
    "            bst_acc = cross_avg_acc\n",
    "            bst_c = c\n",
    "            \n",
    "    #use the C value that worked best (bst_c) for the final testing classifier        \n",
    "    clf = LinearSVC(C=bst_c)\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    trainx = scaler.fit_transform(trainx)\n",
    "    testx = scaler.transform(testx)\n",
    "    trainy = np.ravel(trainy)\n",
    "    testy = np.ravel(testy)\n",
    "    \n",
    "    clf.fit(trainx, trainy)\n",
    "    myscore = clf.score(testx, testy)\n",
    "    avgacc+=myscore\n",
    "\n",
    "    print(\"For \" + index_to_cat[pair[0]] + \" and \" + index_to_cat[pair[1]] + \" we picked C = \" + str(bst_c))\n",
    "    print(\"Has accuracy \" + str(myscore))\n",
    "    print(\"=========\")\n",
    "    \n",
    "print(avgacc/(12*11/2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.674421664194"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
