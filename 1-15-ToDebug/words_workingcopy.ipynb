{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "## classify cats\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "best_feature_vectors = np.load(\"features_train.npy\")\n",
    "test_feature_vectors = np.load(\"features_test.npy\")\n",
    "lengths = np.load(\"category_lengths.npy\")\n",
    "category_info = np.load(\"words_in_categories.npy\")\n",
    "\n",
    "toSelect = 5\n",
    "tEx = 10\n",
    "training_amt = 8\n",
    "testing_amt = 2\n",
    "\n",
    "trainx = np.zeros((0,toSelect * tEx))\n",
    "trainy = np.zeros((training_amt * tot_words))\n",
    "testx = np.zeros((0, toSelect * tEx))\n",
    "testy = np.zeros((testing_amt * tot_words))\n",
    "\n",
    "ytraincnt = 0\n",
    "ytestcnt = 0\n",
    "\n",
    "for pres in range(training_amt):\n",
    "    for word in range(63):\n",
    "        trainx = np.concatenate((trainx, np.reshape(best_feature_vectors[word][pres],(1,toSelect*tEx))), axis=0)\n",
    "        trainy[ytraincnt] = [m for m in range(12) if word in category_info[m]][0]\n",
    "        ytraincnt+=1\n",
    "\n",
    "        if(pres<testing_amt):\n",
    "            testx = np.concatenate((testx, np.reshape(test_feature_vectors[word][pres],(1,toSelect*tEx))), axis=0)\n",
    "            testy[ytestcnt] = [m for m in range(12) if word in category_info[m]][0]\n",
    "            ytestcnt+=1           \n",
    "            \n",
    "#if you want to convert to one-hot encoding, uncomment the 2 lines below:\n",
    "#trainy = keras.utils.to_categorical(trainy, num_classes=12)\n",
    "#testy = keras.utils.to_categorical(testy, num_classes=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(504,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.214285714286\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import pearsonr\n",
    "from heapq import heappush, heappop, heappushpop\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import LinearSVC\n",
    "import itertools\n",
    "import pickle\n",
    "\n",
    "#clist = np.logspace(-4,2,100)\n",
    "\n",
    "training_amt = 8 #num of presentations used for training\n",
    "testing_amt = 2 #num of presentations used for testing\n",
    "toSelect = 5 #num of btc's selected\n",
    "tEx = 10 #number of features per BTC vector\n",
    "\n",
    "avgacc = 0\n",
    "\n",
    "bst_acc = 0\n",
    "bst_c = 1\n",
    "\n",
    "\n",
    "for c in clist:\n",
    "    avg_acc = 0\n",
    "    \n",
    "    for fold in range(4):\n",
    "        fold_sz = int(trainx.shape[0]/4)\n",
    "        valid_x = trainx[(fold_sz*fold):((fold_sz)*(fold+1))]\n",
    "        valid_y = trainy[(fold_sz*fold):((fold_sz)*(fold+1))]\n",
    "        tr_x = np.concatenate((trainx[:(fold_sz*fold)],trainx[((fold+1)*fold_sz):]), axis = 0)\n",
    "        tr_y = np.concatenate((trainy[:(fold_sz*fold)],trainy[((fold+1)*fold_sz):]), axis = 0)\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        tr_x = scaler.fit_transform(tr_x)\n",
    "        valid_x = scaler.transform(valid_x)\n",
    "        tr_y = np.ravel(tr_y)\n",
    "        valid_y = np.ravel(valid_y)\n",
    "\n",
    "        classifier = LinearSVC(C = c)\n",
    "        classifier.fit(tr_x,tr_y)\n",
    "        avg_acc += (classifier.score(valid_x, valid_y))/4.0\n",
    "    if(avg_acc > bst_acc):\n",
    "        bst_acc = avg_acc\n",
    "        bst_c = c\n",
    "\n",
    "    \n",
    "clf = LinearSVC(C=bst_c, multi_class='ovr')\n",
    "scaler = StandardScaler()\n",
    "trainx = scaler.fit_transform(trainx)\n",
    "testx = scaler.transform(testx)\n",
    "trainy = np.ravel(trainy)\n",
    "testy = np.ravel(testy)\n",
    "clf.fit(trainx, trainy)\n",
    "myscore = clf.score(testx, testy)\n",
    "avgacc+=myscore\n",
    "\n",
    "#print(\"For \" + str(pair[0]) + \" and \" + str(pair[1]) + \" we picked C = \" + str(bst_c))\n",
    "#print(\"Has accuracy \" + str(myscore))\n",
    "#print(\"=========\")\n",
    "\n",
    "print(myscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For 5 and 9 we picked C = 1.0\n",
      "Has accuracy 0.6\n",
      "=========\n",
      "For 4 and 7 we picked C = 75.6463327555\n",
      "Has accuracy 0.8\n",
      "=========\n",
      "For 1 and 3 we picked C = 12.3284673944\n",
      "Has accuracy 0.7\n",
      "=========\n",
      "For 10 and 11 we picked C = 49.7702356433\n",
      "Has accuracy 0.85\n",
      "=========\n",
      "For 4 and 8 we picked C = 16.2975083462\n",
      "Has accuracy 0.65\n",
      "=========\n",
      "For 5 and 6 we picked C = 0.657933224658\n",
      "Has accuracy 0.75\n",
      "=========\n",
      "For 2 and 8 we picked C = 6.13590727341\n",
      "Has accuracy 0.666666666667\n",
      "=========\n",
      "For 3 and 11 we picked C = 5.33669923121\n",
      "Has accuracy 0.7\n",
      "=========\n",
      "For 0 and 7 we picked C = 1.51991108295\n",
      "Has accuracy 0.772727272727\n",
      "=========\n",
      "For 4 and 6 we picked C = 18.7381742286\n",
      "Has accuracy 0.6\n",
      "=========\n",
      "For 8 and 9 we picked C = 14.1747416293\n",
      "Has accuracy 0.65\n",
      "=========\n",
      "For 1 and 6 we picked C = 86.9749002618\n",
      "Has accuracy 0.6\n",
      "=========\n",
      "For 0 and 10 we picked C = 43.2876128108\n",
      "Has accuracy 0.727272727273\n",
      "=========\n",
      "For 3 and 7 we picked C = 4.0370172586\n",
      "Has accuracy 0.65\n",
      "=========\n",
      "For 7 and 11 we picked C = 24.7707635599\n",
      "Has accuracy 0.7\n",
      "=========\n",
      "For 0 and 3 we picked C = 0.572236765935\n",
      "Has accuracy 0.863636363636\n",
      "=========\n",
      "For 1 and 11 we picked C = 0.0613590727341\n",
      "Has accuracy 0.35\n",
      "=========\n",
      "For 2 and 5 we picked C = 3.51119173422\n",
      "Has accuracy 0.75\n",
      "=========\n",
      "For 5 and 8 we picked C = 0.0932603346883\n",
      "Has accuracy 0.65\n",
      "=========\n",
      "For 1 and 2 we picked C = 1.0\n",
      "Has accuracy 0.583333333333\n",
      "=========\n",
      "For 4 and 9 we picked C = 0.284803586844\n",
      "Has accuracy 0.8\n",
      "=========\n",
      "For 2 and 9 we picked C = 1.51991108295\n",
      "Has accuracy 0.75\n",
      "=========\n",
      "For 1 and 5 we picked C = 2.31012970008\n",
      "Has accuracy 0.7\n",
      "=========\n",
      "For 3 and 10 we picked C = 14.1747416293\n",
      "Has accuracy 0.6\n",
      "=========\n",
      "For 6 and 10 we picked C = 43.2876128108\n",
      "Has accuracy 0.75\n",
      "=========\n",
      "For 8 and 10 we picked C = 0.756463327555\n",
      "Has accuracy 0.8\n",
      "=========\n",
      "For 4 and 5 we picked C = 10.7226722201\n",
      "Has accuracy 0.45\n",
      "=========\n",
      "For 0 and 11 we picked C = 43.2876128108\n",
      "Has accuracy 0.590909090909\n",
      "=========\n",
      "For 9 and 11 we picked C = 2.65608778295\n",
      "Has accuracy 0.65\n",
      "=========\n",
      "For 7 and 10 we picked C = 86.9749002618\n",
      "Has accuracy 0.5\n",
      "=========\n",
      "For 0 and 4 we picked C = 5.33669923121\n",
      "Has accuracy 0.636363636364\n",
      "=========\n",
      "For 1 and 10 we picked C = 1.74752840001\n",
      "Has accuracy 0.65\n",
      "=========\n",
      "For 3 and 5 we picked C = 18.7381742286\n",
      "Has accuracy 0.55\n",
      "=========\n",
      "For 4 and 10 we picked C = 8.1113083079\n",
      "Has accuracy 0.7\n",
      "=========\n",
      "For 2 and 6 we picked C = 0.0613590727341\n",
      "Has accuracy 0.625\n",
      "=========\n",
      "For 3 and 6 we picked C = 0.0705480231072\n",
      "Has accuracy 0.7\n",
      "=========\n",
      "For 5 and 11 we picked C = 100.0\n",
      "Has accuracy 0.8\n",
      "=========\n",
      "For 6 and 11 we picked C = 8.1113083079\n",
      "Has accuracy 0.6\n",
      "=========\n",
      "For 8 and 11 we picked C = 100.0\n",
      "Has accuracy 0.75\n",
      "=========\n",
      "For 2 and 7 we picked C = 0.497702356433\n",
      "Has accuracy 0.708333333333\n",
      "=========\n",
      "For 1 and 4 we picked C = 86.9749002618\n",
      "Has accuracy 0.65\n",
      "=========\n",
      "For 2 and 10 we picked C = 4.0370172586\n",
      "Has accuracy 0.666666666667\n",
      "=========\n",
      "For 9 and 10 we picked C = 1.0\n",
      "Has accuracy 0.85\n",
      "=========\n",
      "For 3 and 9 we picked C = 28.4803586844\n",
      "Has accuracy 0.65\n",
      "=========\n",
      "For 0 and 5 we picked C = 0.869749002618\n",
      "Has accuracy 0.818181818182\n",
      "=========\n",
      "For 1 and 9 we picked C = 12.3284673944\n",
      "Has accuracy 0.7\n",
      "=========\n",
      "For 6 and 7 we picked C = 0.756463327555\n",
      "Has accuracy 0.7\n",
      "=========\n",
      "For 0 and 8 we picked C = 18.7381742286\n",
      "Has accuracy 0.681818181818\n",
      "=========\n",
      "For 4 and 11 we picked C = 14.1747416293\n",
      "Has accuracy 0.75\n",
      "=========\n",
      "For 7 and 9 we picked C = 8.1113083079\n",
      "Has accuracy 0.75\n",
      "=========\n",
      "For 0 and 1 we picked C = 16.2975083462\n",
      "Has accuracy 0.590909090909\n",
      "=========\n",
      "For 6 and 9 we picked C = 6.13590727341\n",
      "Has accuracy 0.6\n",
      "=========\n",
      "For 5 and 10 we picked C = 16.2975083462\n",
      "Has accuracy 0.7\n",
      "=========\n",
      "For 6 and 8 we picked C = 86.9749002618\n",
      "Has accuracy 0.65\n",
      "=========\n",
      "For 3 and 4 we picked C = 24.7707635599\n",
      "Has accuracy 0.5\n",
      "=========\n",
      "For 5 and 7 we picked C = 1.0\n",
      "Has accuracy 0.4\n",
      "=========\n",
      "For 2 and 11 we picked C = 43.2876128108\n",
      "Has accuracy 0.791666666667\n",
      "=========\n",
      "For 2 and 4 we picked C = 12.3284673944\n",
      "Has accuracy 0.75\n",
      "=========\n",
      "For 3 and 8 we picked C = 6.13590727341\n",
      "Has accuracy 0.55\n",
      "=========\n",
      "For 0 and 6 we picked C = 14.1747416293\n",
      "Has accuracy 0.590909090909\n",
      "=========\n",
      "For 1 and 8 we picked C = 28.4803586844\n",
      "Has accuracy 0.55\n",
      "=========\n",
      "For 1 and 7 we picked C = 65.7933224658\n",
      "Has accuracy 0.75\n",
      "=========\n",
      "For 0 and 9 we picked C = 4.64158883361\n",
      "Has accuracy 0.727272727273\n",
      "=========\n",
      "For 2 and 3 we picked C = 5.33669923121\n",
      "Has accuracy 0.708333333333\n",
      "=========\n",
      "For 7 and 8 we picked C = 2.65608778295\n",
      "Has accuracy 0.75\n",
      "=========\n",
      "For 0 and 2 we picked C = 12.3284673944\n",
      "Has accuracy 0.615384615385\n",
      "=========\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import pearsonr\n",
    "from heapq import heappush, heappop, heappushpop\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import LinearSVC\n",
    "import itertools\n",
    "import pickle\n",
    "\n",
    "file_name = 'CategoryXCategory.p' #change this appropriately\n",
    "\n",
    "loaded_data = pickle.load(open(file_name,\"rb\"))\n",
    "\n",
    "dict_trainx = loaded_data[0]\n",
    "dict_trainy = loaded_data[1]\n",
    "dict_testx = loaded_data[2]\n",
    "dict_testy = loaded_data[3]\n",
    "\n",
    "clist = np.logspace(-4,2,100)\n",
    "\n",
    "training_amt = 8 #num of presentations used for training\n",
    "testing_amt = 2 #num of presentations used for testing\n",
    "toSelect = 5 #num of btc's selected\n",
    "tEx = 10 #number of features per BTC vector\n",
    "\n",
    "avgacc = 0\n",
    "for pair in dict_trainx:\n",
    "    trainx = dict_trainx[pair]\n",
    "    trainy = dict_trainy[pair]\n",
    "    testx = dict_testx[pair]\n",
    "    testy = dict_testy[pair]\n",
    "\n",
    "    bst_acc = 0\n",
    "    bst_c = 0\n",
    "\n",
    "    for c in clist:\n",
    "        avg_acc = 0\n",
    "        for fold in range(4):\n",
    "            fold_sz = int(trainx.shape[0]/4)\n",
    "            valid_x = trainx[(fold_sz*fold):((fold_sz)*(fold+1))]\n",
    "            valid_y = trainy[(fold_sz*fold):((fold_sz)*(fold+1))]\n",
    "            tr_x = np.concatenate((trainx[:(fold_sz*fold)],trainx[((fold+1)*fold_sz):]), axis = 0)\n",
    "            tr_y = np.concatenate((trainy[:(fold_sz*fold)],trainy[((fold+1)*fold_sz):]), axis = 0)\n",
    "\n",
    "            scaler = StandardScaler()\n",
    "            tr_x = scaler.fit_transform(tr_x)\n",
    "            valid_x = scaler.transform(valid_x)\n",
    "            tr_y = np.ravel(tr_y)\n",
    "            valid_y = np.ravel(valid_y)\n",
    "\n",
    "            classifier = LinearSVC(C = c)\n",
    "            classifier.fit(tr_x,tr_y)\n",
    "            avg_acc += (classifier.score(valid_x, valid_y))/4.0\n",
    "        if(avg_acc > bst_acc):\n",
    "            bst_acc = avg_acc\n",
    "            bst_c = c\n",
    "    clf = LinearSVC(C=bst_c)\n",
    "    scaler = StandardScaler()\n",
    "    trainx = scaler.fit_transform(trainx)\n",
    "    testx = scaler.transform(testx)\n",
    "    trainy = np.ravel(trainy)\n",
    "    testy = np.ravel(testy)\n",
    "    clf.fit(trainx, trainy)\n",
    "    myscore = clf.score(testx, testy)\n",
    "    avgacc+=myscore\n",
    "\n",
    "    print(\"For \" + str(pair[0]) + \" and \" + str(pair[1]) + \" we picked C = \" + str(bst_c))\n",
    "    print(\"Has accuracy \" + str(myscore))\n",
    "    print(\"=========\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44.365384615384606"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avgacc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "avgacc /= (12*11/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.67220279720279708"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avgacc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
