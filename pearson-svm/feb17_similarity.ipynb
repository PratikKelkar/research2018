{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import pearsonr\n",
    "import heapq\n",
    "from heapq import heappush, heappop, heappushpop\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import LinearSVC\n",
    "import itertools\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = np.load(\"all_data.npy\") #holds all the data from channels\n",
    "category_info = np.load(\"words_in_categories.npy\") #category_info[cat][ptr] returns the number of the word(0...62) of the ptr'th word in the category cat\n",
    "lengths = np.load(\"category_lengths.npy\") #lengths[cat] is the number of words in category cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_words = 63 \n",
    "\n",
    "tStart = 0 #start time\n",
    "tEnd = 650 #end time\n",
    "tWidth = 100 #width of time slice\n",
    "tIncr = 50 #increment in start time\n",
    "tEx = 10 #number of examples to downsample to\n",
    "tNtoAvg = int(tWidth/tEx) #number of timestep values to average to form one example\n",
    "\n",
    "training_amt = 8 #8 examples for training, 2 for testing\n",
    "testing_amt = 10 - training_amt\n",
    "\n",
    "np.random.seed(63)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainingData = np.zeros((total_words,5,training_amt,256,650))#gives the pertinent data from all_data for the two categories\n",
    "TestingData = np.zeros( (total_words,5,testing_amt,256,650)) #^\n",
    "wordptr = -1 #the index of the current word, iterates from 0...total_words\n",
    "\n",
    "for i in range(63):\n",
    "    wordptr+=1\n",
    "\n",
    "    excl = [-1]*10 #excl[j] = the j'th presentation number which should be saved for testing (e.g. excl[0] = 0 means the first presentation of the wordptr'th word should be saved for testing). Ignore -1's.\n",
    "    \n",
    "    for pres in range(testing_amt):\n",
    "        while(1): #this loop repeatedly generates a random presentation until one which hasn't been reserved for testing has been found, and then breaks it\n",
    "            nxtrand = np.random.randint(0,10)\n",
    "            if(excl[nxtrand]==-1):\n",
    "                excl[nxtrand]=nxtrand\n",
    "                break\n",
    "    for bandnum in range(5):\n",
    "        ptr2 = 0 #points to which presentation(0...9) of wordptr'th word we are currently copying to TrainingData\n",
    "        for pres in range(10):\n",
    "            if(excl[pres]!=-1): #if reserved for testing, don't include in training data\n",
    "                continue\n",
    "           \n",
    "            TrainingData[wordptr][bandnum][ptr2]=all_data[bandnum][i][pres] #sets the channel x time matrix for TrainingData[bandnum][wordptr][ptr2]\n",
    "            ptr2+=1 #move to next presentation\n",
    "\n",
    "    for bandnum in range(5): #this loop is same as above, except now we only want the testing presentations\n",
    "        ptr2=0\n",
    "        for pres in range(10):\n",
    "            if(excl[pres]==-1):\n",
    "                continue\n",
    "            TestingData[wordptr][bandnum][ptr2] = all_data[bandnum][i][excl[pres]]\n",
    "            ptr2+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "toSelect = 5 #number of top features to select\n",
    "\n",
    "train_feature_vectors = np.zeros((total_words, training_amt,toSelect * tEx))\n",
    "test_feature_vectors = np.zeros((total_words, testing_amt, toSelect * tEx))\n",
    "timeSequences = np.zeros((total_words,5,12,training_amt,256,tEx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 12, 256, 63, 8, 10)\n"
     ]
    }
   ],
   "source": [
    "time_pointer = 0\n",
    "for t in range(tStart, tEnd-tWidth+1, tIncr):\n",
    "    tEx_pointer = 0\n",
    "    for tEStart in range(t,t+tWidth-tEx+1,tNtoAvg):\n",
    "        timeSequences[:,:,time_pointer,:,:,tEx_pointer] = np.average(TrainingData[:,:,:,:,tEStart:tEStart+tNtoAvg], axis = 4)\n",
    "        tEx_pointer+=1\n",
    "    time_pointer+=1\n",
    "\n",
    "btcwpv_matrix = np.transpose(timeSequences, (1, 2, 4, 0, 3, 5)) #band,time,channel,word,pres,value matrix in that order\n",
    "print(btcwpv_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTools 29.951406328\n",
      "\tAnimals 31.5223048562\n",
      "\tBuildings 25.3300220892\n",
      "\tBody Parts 20.282115635\n",
      "\tFurniture 29.9131665937\n",
      "\tVehicles 30.3536025496\n",
      "\tKitchen Utensils 19.770727642\n",
      "\tBuilding Parts 28.2914487204\n",
      "\tClothing 35.0384274227\n",
      "\tInsects 57.5985880093\n",
      "\tVegetables 26.6776789374\n",
      "\tMan-made objects 30.3252509962\n",
      "=====================================================\n",
      "Tools\n",
      "\tTools 29.951406328\n",
      "\tAnimals 32.6344233015\n",
      "\tBuildings 26.9983456565\n",
      "\tBody Parts 19.7452904928\n",
      "\tFurniture 30.418159969\n",
      "\tVehicles 30.8741838788\n",
      "\tKitchen Utensils 19.0480165789\n",
      "\tBuilding Parts 28.4404169875\n",
      "\tClothing 35.3989675172\n",
      "\tInsects 64.1922018265\n",
      "\tVegetables 29.1278673491\n",
      "\tMan-made objects 30.207744081\n",
      "Animals\n",
      "\tTools 29.8103551773\n",
      "\tAnimals 31.5223048562\n",
      "\tBuildings 26.0374081308\n",
      "\tBody Parts 20.2700329637\n",
      "\tFurniture 29.5408058501\n",
      "\tVehicles 30.5271059493\n",
      "\tKitchen Utensils 19.3174109158\n",
      "\tBuilding Parts 28.4644898801\n",
      "\tClothing 34.8436647652\n",
      "\tInsects 62.3108959825\n",
      "\tVegetables 27.6314792585\n",
      "\tMan-made objects 30.2742084909\n",
      "Buildings\n",
      "\tTools 29.3181951256\n",
      "\tAnimals 31.2671112937\n",
      "\tBuildings 25.3300220892\n",
      "\tBody Parts 19.4096658461\n",
      "\tFurniture 29.2749146585\n",
      "\tVehicles 30.1286223479\n",
      "\tKitchen Utensils 18.3046262346\n",
      "\tBuilding Parts 27.5740681506\n",
      "\tClothing 34.7493471984\n",
      "\tInsects 62.2734503588\n",
      "\tVegetables 27.3246512502\n",
      "\tMan-made objects 29.8192112112\n",
      "Body Parts\n",
      "\tTools 30.7957020909\n",
      "\tAnimals 34.0254798091\n",
      "\tBuildings 28.7280032641\n",
      "\tBody Parts 20.282115635\n",
      "\tFurniture 31.5345189539\n",
      "\tVehicles 31.7954062827\n",
      "\tKitchen Utensils 20.0670536601\n",
      "\tBuilding Parts 29.4892313656\n",
      "\tClothing 36.131394315\n",
      "\tInsects 65.9020725336\n",
      "\tVegetables 30.8665699358\n",
      "\tMan-made objects 30.7639935144\n",
      "Furniture\n",
      "\tTools 29.4108244519\n",
      "\tAnimals 32.0343752215\n",
      "\tBuildings 26.0395311302\n",
      "\tBody Parts 18.8617914612\n",
      "\tFurniture 29.9131665937\n",
      "\tVehicles 30.3003222221\n",
      "\tKitchen Utensils 18.1287515914\n",
      "\tBuilding Parts 27.5104903887\n",
      "\tClothing 35.0884405648\n",
      "\tInsects 63.562331639\n",
      "\tVegetables 28.461061302\n",
      "\tMan-made objects 29.81355609\n",
      "Vehicles\n",
      "\tTools 29.5284301859\n",
      "\tAnimals 31.9981378953\n",
      "\tBuildings 26.2246875874\n",
      "\tBody Parts 19.2591869362\n",
      "\tFurniture 29.9205683904\n",
      "\tVehicles 30.3536025496\n",
      "\tKitchen Utensils 18.529112436\n",
      "\tBuilding Parts 27.8349748513\n",
      "\tClothing 35.0761332653\n",
      "\tInsects 63.4480379144\n",
      "\tVegetables 28.4313086422\n",
      "\tMan-made objects 29.9501352758\n",
      "Kitchen Utensils\n",
      "\tTools 30.7233434547\n",
      "\tAnimals 33.7115872779\n",
      "\tBuildings 27.7204311096\n",
      "\tBody Parts 20.5375101058\n",
      "\tFurniture 31.1682481552\n",
      "\tVehicles 32.0506943065\n",
      "\tKitchen Utensils 19.770727642\n",
      "\tBuilding Parts 29.7474130754\n",
      "\tClothing 36.4343603167\n",
      "\tInsects 65.1753098703\n",
      "\tVegetables 29.988193083\n",
      "\tMan-made objects 30.6276951888\n",
      "Building Parts\n",
      "\tTools 29.7407992492\n",
      "\tAnimals 32.0245680648\n",
      "\tBuildings 26.4826826384\n",
      "\tBody Parts 19.6819311225\n",
      "\tFurniture 29.9095390914\n",
      "\tVehicles 30.5057656559\n",
      "\tKitchen Utensils 18.942174526\n",
      "\tBuilding Parts 28.2914487204\n",
      "\tClothing 35.1014533178\n",
      "\tInsects 63.4166958979\n",
      "\tVegetables 28.4280433181\n",
      "\tMan-made objects 30.0772892472\n",
      "Clothing\n",
      "\tTools 29.1532010649\n",
      "\tAnimals 31.8956386189\n",
      "\tBuildings 25.7043782998\n",
      "\tBody Parts 18.785244024\n",
      "\tFurniture 29.764372217\n",
      "\tVehicles 30.1521500805\n",
      "\tKitchen Utensils 17.9010212669\n",
      "\tBuilding Parts 27.5454973107\n",
      "\tClothing 35.0384274227\n",
      "\tInsects 63.4434009637\n",
      "\tVegetables 28.2043672443\n",
      "\tMan-made objects 29.659256993\n",
      "Insects\n",
      "\tTools 28.3748775471\n",
      "\tAnimals 28.3944721824\n",
      "\tBuildings 21.6846415247\n",
      "\tBody Parts 19.7366873241\n",
      "\tFurniture 26.5682261518\n",
      "\tVehicles 29.2101312475\n",
      "\tKitchen Utensils 17.6156382911\n",
      "\tBuilding Parts 27.2649545178\n",
      "\tClothing 33.5879388086\n",
      "\tInsects 57.5985880093\n",
      "\tVegetables 22.9819755938\n",
      "\tMan-made objects 29.126629696\n",
      "Vegetables\n",
      "\tTools 28.950111151\n",
      "\tAnimals 30.8496314455\n",
      "\tBuildings 24.6591657433\n",
      "\tBody Parts 19.1623781054\n",
      "\tFurniture 28.8396272709\n",
      "\tVehicles 29.864702829\n",
      "\tKitchen Utensils 17.9199235708\n",
      "\tBuilding Parts 27.612145315\n",
      "\tClothing 34.5918854087\n",
      "\tInsects 61.787741036\n",
      "\tVegetables 26.6776789374\n",
      "\tMan-made objects 29.5205525597\n",
      "Man-made objects\n",
      "\tTools 30.2336135829\n",
      "\tAnimals 33.8170374486\n",
      "\tBuildings 27.9981411495\n",
      "\tBody Parts 19.3538752426\n",
      "\tFurniture 31.4033000412\n",
      "\tVehicles 31.4012475093\n",
      "\tKitchen Utensils 18.9185133795\n",
      "\tBuilding Parts 28.4131704675\n",
      "\tClothing 36.0281186956\n",
      "\tInsects 65.9622690539\n",
      "\tVegetables 30.6760910265\n",
      "\tMan-made objects 30.3252509962\n"
     ]
    }
   ],
   "source": [
    "index_to_cat = [\"Tools\",\"Animals\",\"Buildings\",\"Body Parts\",\"Furniture\",\"Vehicles\",\"Kitchen Utensils\", \n",
    "\"Building Parts\", \"Clothing\", \"Insects\", \"Vegetables\",\"Man-made objects\"]\n",
    "\n",
    "_b_fix = 0\n",
    "_t_fix = 2\n",
    "_c_fix = 100\n",
    "\n",
    "def word_averaged(word, btcwpv_matrix):\n",
    "    word_averaged = np.zeros((10)) \n",
    "    for pres_counter in range(8):\n",
    "        word_averaged += btcwpv_matrix[_b_fix, _t_fix, _c_fix, word, pres_counter]\n",
    "    return word_averaged\n",
    "            \n",
    "for cat in range(12):\n",
    "    M1 = 0\n",
    "    for word in category_info[cat]:\n",
    "        if word!=-1:\n",
    "            for pres in range(8):\n",
    "                for other_word in category_info[cat]:\n",
    "                        if other_word!=-1:\n",
    "                            M1 += np.linalg.norm(btcwpv_matrix[_b_fix, _t_fix, _c_fix, word, pres] \n",
    "                                                 - word_averaged(other_word, btcwpv_matrix))\n",
    "    print(\"\\t\" + index_to_cat[cat] + \" \" + str(M1/(lengths[cat][0]*8*lengths[cat][0])))\n",
    "\n",
    "print(\"=====================================================\")\n",
    "\n",
    "\n",
    "for cat1 in range(12):\n",
    "    print(index_to_cat[cat1])\n",
    "    for cat2 in range(12):\n",
    "        M2 = 0\n",
    "        for word in category_info[cat1]:\n",
    "            if word!=-1:\n",
    "                for pres in range(8):\n",
    "                    for other_word in category_info[cat2]:\n",
    "                        if other_word!=-1:\n",
    "                            M2 += np.linalg.norm(btcwpv_matrix[_b_fix, _t_fix, _c_fix, word, pres] \n",
    "                                                 - word_averaged(other_word, btcwpv_matrix))\n",
    "        print(\"\\t\" + index_to_cat[cat2] + \" \" + str(M2/(lengths[cat1][0]*8*lengths[cat2][0])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150\n",
      "300\n",
      "450\n",
      "600\n",
      "750\n",
      "900\n",
      "1050\n",
      "1200\n",
      "1350\n",
      "1500\n",
      "1650\n",
      "1800\n",
      "1950\n",
      "2100\n",
      "2250\n",
      "2400\n",
      "2550\n",
      "2700\n",
      "2850\n",
      "3000\n",
      "3150\n",
      "3300\n",
      "3450\n",
      "3600\n",
      "3750\n",
      "3900\n",
      "4050\n",
      "4200\n",
      "4350\n",
      "4500\n",
      "4650\n",
      "4800\n",
      "4950\n",
      "5100\n",
      "5250\n",
      "5400\n",
      "5550\n",
      "5700\n",
      "5850\n",
      "6000\n",
      "6150\n",
      "6300\n",
      "6450\n",
      "6600\n",
      "6750\n",
      "6900\n",
      "7050\n",
      "7200\n",
      "7350\n",
      "7500\n",
      "7650\n",
      "7800\n",
      "7950\n",
      "8100\n",
      "8250\n",
      "8400\n",
      "8550\n",
      "8700\n",
      "8850\n",
      "9000\n",
      "9150\n",
      "9300\n",
      "9450\n",
      "9600\n",
      "9750\n",
      "9900\n",
      "10050\n",
      "10200\n",
      "10350\n",
      "10500\n",
      "10650\n",
      "10800\n",
      "10950\n",
      "11100\n",
      "11250\n",
      "11400\n",
      "11550\n",
      "11700\n",
      "11850\n",
      "12000\n",
      "12150\n",
      "12300\n",
      "12450\n",
      "12600\n",
      "12750\n",
      "12900\n",
      "13050\n",
      "13200\n",
      "13350\n",
      "13500\n",
      "13650\n",
      "13800\n",
      "13950\n",
      "14100\n",
      "14250\n",
      "14400\n",
      "14550\n",
      "14700\n",
      "14850\n",
      "15000\n",
      "15150\n",
      "15300\n",
      "(99.223998464555663, 0, 10, 254)\n",
      "(-9.467752802818147, 0, 1, 223)\n",
      "(-3.9894980054611944, 4, 11, 254)\n",
      "(76.425304476261232, 0, 3, 243)\n",
      "(37.765130176222961, 0, 6, 39)\n"
     ]
    }
   ],
   "source": [
    "tools = 0\n",
    "animals = 1\n",
    "\n",
    "#store_values_arr = np.zeros((5*12*256, 4))\n",
    "\n",
    "store_values_counter = 0\n",
    "\n",
    "store_vals_heap = []\n",
    "for _b_fix in range(5):\n",
    "    for _t_fix in range(12):\n",
    "        for _c_fix in range(256):\n",
    "            \n",
    "            TvT = 0\n",
    "            TvA = 0 \n",
    "            for word in category_info[tools]:\n",
    "                if word!=-1:\n",
    "                    for pres in range(8):\n",
    "                        for other_word in category_info[tools]:\n",
    "                            if other_word!=-1:\n",
    "                                TvT += np.linalg.norm(btcwpv_matrix[_b_fix, _t_fix, _c_fix, word, pres] \n",
    "                                                     - word_averaged(other_word, btcwpv_matrix))\n",
    "                                \n",
    "                        for other_word in category_info[animals]:\n",
    "                            if other_word!=-1:\n",
    "                                TvA += np.linalg.norm(btcwpv_matrix[_b_fix, _t_fix, _c_fix, word, pres] \n",
    "                                                        - word_averaged(other_word, btcwpv_matrix))\n",
    "            \n",
    "            TvT = TvT/(lengths[tools][0]*8*lengths[tools][0])\n",
    "            TvA = TvA/(lengths[tools][0]*8*lengths[animals][0])\n",
    "            \n",
    "            #store_values_arr[store_values_counter, 0] = TvA - TvT\n",
    "            #store_values_arr[store_values_counter, 1] = _b_fix\n",
    "            #store_values_arr[store_values_counter, 2] = _t_fix\n",
    "            #store_values_arr[store_values_counter, 3] = _c_fix\n",
    "            \n",
    "            store_values_counter+=1\n",
    "            \n",
    "            if store_values_counter%150==0:\n",
    "                print(store_values_counter)\n",
    "            \n",
    "            store_vals_heap.append((TvA-TvT, _b_fix, _t_fix, _c_fix))\n",
    "\n",
    "heapq._heapify_max(store_vals_heap)\n",
    "for i in range(5):\n",
    "    print(heappop(store_vals_heap))\n",
    "\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99.2239984646 93.7660544526 93.7660544526\n",
      "(0.0, 2.0, 243.0)\n",
      "(0, 0, 0)\n",
      "(0, 0, 0)\n"
     ]
    }
   ],
   "source": [
    "max1 = 0\n",
    "_btc1 = (0,0,0)\n",
    "for i in store_values_arr:\n",
    "    if i[0] > max1:\n",
    "        max1 = i[0]\n",
    "        _btc1 = (i[1], i[2], i[3])\n",
    "        \n",
    "max2 = 0\n",
    "_btc2 = (0,0,0)\n",
    "for i in store_values_arr:\n",
    "    if i[0] > max2:\n",
    "        if i[0] < max1:\n",
    "            max2 = i[0]\n",
    "            _btc1 = (i[1], i[2], i[3])\n",
    "        \n",
    "max3 = 0\n",
    "_btc3 = (0,0,0)\n",
    "for i in store_values_arr:\n",
    "    if i[0] > max3:\n",
    "        if i[0] < max2:\n",
    "            max3 = i[0]\n",
    "            _btc1 = (i[1], i[2], i[3])\n",
    "\n",
    "print(max1, max2,max2)\n",
    "print(_btc1)\n",
    "print(_btc2)\n",
    "print(_btc3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num words\n",
    "num bands\n",
    "num time sections\n",
    "num presentations\n",
    "num channels\n",
    "num timesteps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "useless = ''' \n",
    "for wordnum in range(total_words):\n",
    "    SHheap = [] #heap of BTC + featurevector information used to select top 400\n",
    "    \n",
    "    for band_num in range(5): #frequency bands\n",
    "        time_pointer=0\n",
    "        for t in range(tStart, tEnd-tWidth+1, tIncr): #various starts of time slice\n",
    "            for channel in range(256): #eeg channels\n",
    "\n",
    "                #pairwise correlations\n",
    "                avg_p = 0\n",
    "    \n",
    "                for i in range(training_amt-1):\n",
    "                    for j in range(i+1,training_amt):\n",
    "\n",
    "                        avg_p += pearsonr(timeSequences[wordnum][band_num][time_pointer][i][channel],timeSequences[wordnum][band_num][time_pointer][j][channel])[0]\n",
    "\n",
    "                avg_p /= training_amt*(training_amt-1)/2 #want to maximize\n",
    "                \n",
    "                if(len(SHheap)<400):\n",
    "                    heappush(SHheap, (avg_p,band_num,t,channel, timeSequences[wordnum,band_num,time_pointer,:,channel]))\n",
    "                else:\n",
    "                    heappushpop(SHheap, (avg_p,band_num,t,channel, timeSequences[wordnum,band_num,time_pointer,:,channel]))\n",
    "            time_pointer+=1\n",
    "\n",
    "    print(\"Word \" + str(wordnum))\n",
    "\n",
    "    \n",
    "    current_matrix = np.zeros( (training_amt,0))\n",
    "    test_matrix = np.zeros( (testing_amt,0))\n",
    "    \n",
    "    for i in range(400):\n",
    "        (avg_p,band_num,t,channel, timeSequenc) = heappop(SHheap)\n",
    "        if(i>=400-toSelect):\n",
    "            print(str(400-i) + \". \" + str(band_num) + \"   \" + str(t) + \"   \" + str(channel) + \"   \" + str(avg_p))\n",
    "            current_matrix = np.hstack( (current_matrix,timeSequenc))\n",
    "\n",
    "            #construct testing matrix\n",
    "            tmpo = np.zeros( (testing_amt,tEx))\n",
    "            for itero in range(testing_amt):\n",
    "                pp = 0\n",
    "                for tEStart in range(t,t+tWidth-tEx+1,tEx):\n",
    "                    tmpo[itero][pp] = np.average(TestingData[wordnum,band_num,itero,channel,tEStart:tEStart+int(tWidth/tEx)])\n",
    "                    pp+=1\n",
    "            test_matrix = np.hstack( (test_matrix,tmpo) )\n",
    "            \n",
    "    train_feature_vectors[wordnum] = current_matrix\n",
    "    test_feature_vectors[wordnum] = test_matrix \n",
    "    ''' "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
